{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Process \n",
    "Nesta etapa vamos estar realizando a limpeza do dataset na seguinte ordem:\n",
    "\n",
    "1. Identificação dos dados faltantes\n",
    "2. Valores inválidos \n",
    "3. Consistência entre colunas \n",
    "4. Duplicatas e Datas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das Bibliotecas\n",
    "import pandas as pd  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Identificação de dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores Problemáticos por Coluna:\n",
      "Transaction ID         0\n",
      "Item                 969\n",
      "Quantity             479\n",
      "Price Per Unit       533\n",
      "Total Spent          502\n",
      "Payment Method      3178\n",
      "Location            3961\n",
      "Transaction Date     460\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importando o dataset \n",
    "df = pd.read_csv(\"dirty_cafe_sales.csv\")\n",
    "\n",
    "# Contar valores ausentes e Inválidos\n",
    "missing_stats = df.apply(lambda x: x.isin(['UNKNOWN', 'ERROR', 'None', np.nan]).sum())\n",
    "print('Valores Problemáticos por Coluna:')\n",
    "print(missing_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução para Item e Payment Method \n",
    "df['Item'] = df['Item'].replace(['UNKNOWN', 'ERROR', 'None'], np.nan)\n",
    "df['Payment Method'] = df['Payment Method'].replace(['UNKNOWN', 'ERROR', 'None'], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Valores inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidades Inválidas: 479 registros\n"
     ]
    }
   ],
   "source": [
    "# Identificar valores não numéricos\n",
    "invalid_quantity = pd.to_numeric(df['Quantity'], errors='coerce').isna().sum()\n",
    "print(f\"Quantidades Inválidas: {invalid_quantity} registros\")\n",
    "\n",
    "# Substituir por 1 (suposição conservadora) ou remover\n",
    "df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce').fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correção de preços\n",
    "price_map = {\n",
    "    'Coffee' : 2, 'Tea': 1.5, 'Sandwich': 4, 'Salad': 5,\n",
    "    'Cake': 3, 'Cookie': 1, 'Smoothie': 4, 'Juice': 3\n",
    "}\n",
    "\n",
    "# Corrigir os preços usando item por refrência\n",
    "df['Price Per Unit'] = df.apply(\n",
    "    lambda row: price_map[row['Item']] if (row['Item'] in price_map) else row['Price Per Unit'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Consistência entre colunas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir valores inválidos e converter para float\n",
    "df['Total Spent'] = df['Total Spent'].replace(['ERROR', 'UNKNOWN', 'None'], np.nan)\n",
    "df['Total Spent'] = (\n",
    "    pd.to_numeric(df['Total Spent'].astype(str).str.replace(',', '.'), errors='coerce')\n",
    ")\n",
    "\n",
    "# Preencher valores ausentes com Quantity * Price Per Unit\n",
    "df['Total Spent'] = df['Total Spent'].fillna(df['Quantity'] * df['Price Per Unit'])\n",
    "\n",
    "# Remover linhas com Total Spent ausente\n",
    "df = df.dropna(subset=['Total Spent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituir variações de texto\n",
    "df['Location'] = df['Location'].str.replace(r'\\bIn[-\\s]?[Ss]tore\\b', 'In-store', regex=True)\n",
    "df['Location'] = df['Location'].str.replace('Takeaway', 'Takeout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Duplicatas e Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transsações duplicadas: 0 registros\n"
     ]
    }
   ],
   "source": [
    "# verificar duplicatas\n",
    "duplicates = df.duplicated(subset=['Transaction ID'], keep=False)\n",
    "print(f'Transsações duplicadas: {duplicates.sum()} registros')\n",
    "\n",
    "# Remover duplicatas (mantendo a primeira ocorrência)\n",
    "df = df.drop_duplicates(subset=['Transaction ID'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter para datetime e identificar inválidos\n",
    "df['Transaction Date'] = pd.to_datetime(df['Transaction Date'], errors='coerce')\n",
    "invalid_dates = df['Transaction Date'].isna().sum()\n",
    "\n",
    "# Remover registros com datas inválidas\n",
    "df = df.dropna(subset=['Transaction Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros restantes após remoção: 8613\n",
      "Método de pagamento mais comum: Digital Wallet\n",
      "Valores ausentes por coluna após limpeza final:\n",
      "Transaction ID      0\n",
      "Item                0\n",
      "Quantity            0\n",
      "Price Per Unit      0\n",
      "Total Spent         0\n",
      "Payment Method      0\n",
      "Location            0\n",
      "Transaction Date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remover linhas onde Item está ausente (já que Price Per Unit também estará ausente)\n",
    "df = df.dropna(subset=['Item', 'Price Per Unit'])\n",
    "\n",
    "print(f\"Registros restantes após remoção: {len(df)}\")\n",
    "\n",
    "moda_pagamento = df['Payment Method'].mode()[0]  # Ex: 'Credit Card'\n",
    "df['Payment Method'] = df['Payment Method'].fillna(moda_pagamento)\n",
    "\n",
    "print(f\"Método de pagamento mais comum: {moda_pagamento}\")\n",
    "\n",
    "df['Location'] = df['Location'].fillna('Unknown')\n",
    "\n",
    "print(\"Valores ausentes por coluna após limpeza final:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando Dataset Tratado\n",
    "df.to_csv('clean_cafe_sales.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
